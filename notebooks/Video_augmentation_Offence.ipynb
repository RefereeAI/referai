{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613dd5a5",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En este notebook se crearán los videos correspondientes a las acciones 'No offence' con el objetivo de compensar el desequilibrio del conjunto de datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ef706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import shutil\n",
    "import vidaug.augmentors as va\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from PIL import ImageOps, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ab758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de lectura de las etiquetas a partir de un json\n",
    "def load_foul_labels(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    action_labels = {}\n",
    "    for action_id, action_data in data['Actions'].items():\n",
    "        label = action_data['Offence']  # Extraer la etiqueta de 'Offence'\n",
    "        action_name = f\"action_{action_id}\"  # Formar el nombre de la acción\n",
    "        action_labels[action_name] = label\n",
    "    \n",
    "    return action_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5345114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de etiquetas en un listado ordenado \n",
    "ls = load_foul_labels(\"F:/data/mvfouls/train/annotations.json\")\n",
    "ls = sorted(ls.items())\n",
    "sorted_labels_train = sorted(ls, key=lambda x: int(x[0].split('_')[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la distribución de clases\n",
    "\n",
    "df = pd.DataFrame(sorted_labels_train, columns=['action', 'label'])\n",
    "\n",
    "# Contar la frecuencia de cada clase\n",
    "class_counts = Counter(df['label'])\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f84c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para agrupar la ruta de los videos por accion  \n",
    "\n",
    "def group_videos_by_action(root_path, video_extensions=None):\n",
    "    \"\"\"\n",
    "    Agrupa videos por acción según el nombre de las carpetas contenedoras.\n",
    "\n",
    "    Args:\n",
    "        root_path (str): Ruta raíz desde donde empezar a buscar.\n",
    "        video_extensions (list, optional): Lista de extensiones de video a buscar.\n",
    "                                           Si no se proporciona, usará valores predeterminados.\n",
    "    Returns:\n",
    "        dict: Diccionario donde las claves son nombres de acciones (carpetas)\n",
    "              y los valores son listas de rutas de videos.\n",
    "    \"\"\"\n",
    "    if video_extensions is None:\n",
    "        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv']\n",
    "\n",
    "    grouped_videos = defaultdict(list)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        for file in filenames:\n",
    "            if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "                action_name = os.path.basename(dirpath)  \n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                grouped_videos[action_name].append(file_path)\n",
    "    \n",
    "    sorted_actions = sorted(\n",
    "        grouped_videos.items(), \n",
    "        key=lambda x: int(x[0].split('_')[1])  # Extraer número después de \"action_\"\n",
    "    )\n",
    "    return grouped_videos\n",
    "\n",
    "root_path = \"F:/data/mvfouls/train\"  #Ruta de los videos para agrupar\n",
    "videos_path = group_videos_by_action(root_path = root_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa808b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones para cargar los videos y guardar los nuevos creados a partir de la función de data augmentation.\n",
    "\n",
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def save_video(frames, output_path, fps=30):\n",
    "    height, width, layers = frames[0].shape\n",
    "    size = (width, height)\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, size)\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "#Función que identifica las acciones con etiqueta No offence y crea una lista aleatoria de acciones para editar   \n",
    "def identify_and_resample_no_offence(actions, labels, target_count):\n",
    "    no_offence_actions = [action for action, label in labels.items() if label == 'No offence']\n",
    "    resampled_actions = resample(no_offence_actions, replace=True, n_samples=target_count, random_state=123)\n",
    "    return resampled_actions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f904cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import vidaug.augmentors as va\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from PIL import ImageOps, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d799a62",
   "metadata": {},
   "source": [
    "# Data Augmentation para Videos Etiquetados como 'No offence'\n",
    "\n",
    "Este código implementa un conjunto de funciones para realizar **data augmentation** en videos etiquetados como `'No offence'`, con el objetivo de equilibrar un conjunto de datos de entrenamiento. A continuación, se describen las transformaciones aplicadas:\n",
    "\n",
    "## Transformaciones\n",
    "\n",
    "1. **Transformaciones básicas con `vidaug`**:\n",
    "   - **Rotación horizontal**: Voltea los frames horizontalmente.\n",
    "   - **Rotación vertical**: Voltea los frames verticalmente.\n",
    "   - **Aumento de brillo**: Incrementa el brillo de los frames.\n",
    "\n",
    "2. **Transformaciones adicionales**:\n",
    "   - **`add_colored_dots`**: Agrega puntos de colores (rojos, negros y blancos) semi-transparentes a los frames para aumentar la variedad visual.\n",
    "   - **`smooth_rotation`**: Aplica una rotación fluida a lo largo de los frames, controlando el ángulo máximo y la velocidad de rotación.\n",
    "\n",
    "## Aplicación en `augment_video`\n",
    "\n",
    "La función `augment_video` toma una lista de frames y aplica secuencialmente las transformaciones mencionadas, combinando las operaciones de `vidaug` y las funciones adicionales para generar videos con mayor diversidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6c6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adjust_saturation(image, factor=1.5):\n",
    "    \"\"\"\n",
    "    Ajusta la saturación de una imagen usando OpenCV.\n",
    "    :param image: Imagen en formato numpy array (BGR).\n",
    "    :param factor: Factor de aumento de saturación.\n",
    "    :return: Imagen con saturación ajustada.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * factor, 0, 255)  # Aumenta saturación\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def adjust_brightness(image, factor=1.2):\n",
    "    \"\"\"\n",
    "    Ajusta el brillo de una imagen multiplicando el canal V en el espacio HSV.\n",
    "    :param image: Imagen en formato numpy array (BGR).\n",
    "    :param factor: Factor de aumento o disminución del brillo.\n",
    "    :return: Imagen con brillo ajustado.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    hsv[..., 2] = np.clip(hsv[..., 2] * factor, 0, 255)  # Ajusta el brillo\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def add_random_noise(image, intensity=15):\n",
    "    \"\"\"\n",
    "    Agrega ruido gaussiano aleatorio a la imagen.\n",
    "    :param image: Imagen en formato numpy array.\n",
    "    :param intensity: Intensidad del ruido.\n",
    "    :return: Imagen con ruido añadido.\n",
    "    \"\"\"\n",
    "    noise = np.random.randint(-intensity, intensity, image.shape, dtype=np.int16)\n",
    "    noisy_image = np.clip(image.astype(np.int16) + noise, 0, 255)  # Mantiene valores en rango\n",
    "    return noisy_image.astype(np.uint8)\n",
    "\n",
    "def apply_gaussian_blur(image, ksize=(5,5)):\n",
    "    \"\"\"\n",
    "    Aplica un desenfoque gaussiano a la imagen.\n",
    "    :param image: Imagen en formato numpy array.\n",
    "    :param ksize: Tamaño del kernel para el desenfoque.\n",
    "    :return: Imagen suavizada.\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(image, ksize, 0)\n",
    "\n",
    "def smooth_rotation(frames, max_angle=10, speed_factor=4):\n",
    "    \"\"\"\n",
    "    Aplica una rotación más rápida y fluida a lo largo de los frames.\n",
    "    :param frames: Lista de frames (numpy arrays).\n",
    "    :param max_angle: Ángulo máximo de rotación en grados.\n",
    "    :param speed_factor: Factor de velocidad para hacer la rotación más rápida.\n",
    "    :return: Lista de frames rotados suavemente.\n",
    "    \"\"\"\n",
    "    num_frames = len(frames)\n",
    "    angles = max_angle * np.sin(np.linspace(-np.pi * speed_factor, np.pi * speed_factor, num_frames))\n",
    "\n",
    "    rotated_frames = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        angle = angles[i]  # Toma el ángulo correspondiente al frame\n",
    "        (h, w) = frame.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "        rotated_frame = cv2.warpAffine(frame, M, (w, h), borderMode=cv2.BORDER_REFLECT)  # Evita bordes negros\n",
    "        rotated_frames.append(rotated_frame)\n",
    "\n",
    "    return rotated_frames\n",
    "\n",
    "def add_colored_dots(image, num_dots=1000, dot_size=2, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Agrega puntos rojos, negros y blancos semi-transparentes a la imagen.\n",
    "    :param image: Frame en formato numpy array (BGR).\n",
    "    :param num_dots: Número total de puntos a dibujar.\n",
    "    :param dot_size: Tamaño de cada punto en píxeles.\n",
    "    :param alpha: Opacidad del efecto (0 = invisible, 1 = sólido).\n",
    "    :return: Imagen con efecto de puntitos de diferentes colores.\n",
    "    \"\"\"\n",
    "    overlay = image.copy()\n",
    "    h, w = image.shape[:2]\n",
    "    colors = [(0, 0, 255), (0, 0, 0), (255, 255, 255)]  # Rojo, Negro, Blanco\n",
    "\n",
    "    for _ in range(num_dots):\n",
    "        x, y = random.randint(0, w - 1), random.randint(0, h - 1)\n",
    "        color = random.choice(colors)  # Selecciona un color aleatorio\n",
    "        cv2.circle(overlay, (x, y), dot_size, color, -1)\n",
    "\n",
    "    return cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)  # Mezcla las capas\n",
    "\n",
    "def augment_video(frames, rotate_every=10):\n",
    "    \"\"\"\n",
    "    Aplica transformaciones de `vidaug`, rota cada cierto número de frames y añade puntos de colores.\n",
    "    :param frames: Lista de frames (numpy arrays en formato BGR).\n",
    "    :param rotate_every: Número de frames después del cual se aplica una rotación.\n",
    "    :return: Lista de frames transformados.\n",
    "    \"\"\"\n",
    "     \n",
    "    transformed_frames = []\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        if i % rotate_every == 0:  # Rotar cada 'rotate_every' frames\n",
    "            angle = random.uniform(-5, 5)\n",
    "            (h, w) = frame.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "            frame = cv2.warpAffine(frame, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "        frame = add_colored_dots(frame, num_dots=500, dot_size=2, alpha=0.6)  # Agregar puntitos de colores\n",
    "        transformed_frames.append(frame)\n",
    "\n",
    "    return np.array(transformed_frames)\n",
    "\n",
    "def navigate_and_resample_videos(base_path, actions, resampled_actions):\n",
    "    for action in resampled_actions:  # Iteramos sobre la lista de acciones resampleadas\n",
    "        if action in actions:\n",
    "            video_list = actions[action]  # Obtenemos los videos asociados a la acción\n",
    "            \n",
    "            # Crear una única carpeta para guardar todos los videos aumentados de esta acción\n",
    "            new_action_path = os.path.join(base_path, f\"{action}_augmented\")\n",
    "            os.makedirs(new_action_path, exist_ok=True)\n",
    "            \n",
    "            for video_file in video_list:\n",
    "                video_path = os.path.join(base_path, video_file)\n",
    "                \n",
    "                frames = load_video(video_path)\n",
    "                if len(frames) == 0:\n",
    "                    print(f\"Advertencia: No se encontraron frames en {video_path}, saltando...\")\n",
    "                    continue\n",
    "\n",
    "                augmented_frames = augment_video(frames) \n",
    "                \n",
    "                # Nombre del archivo de salida dentro de la carpeta de la acción\n",
    "                video_name = os.path.splitext(os.path.basename(video_file))[0]  # Quita la extensión\n",
    "                output_video_path = os.path.join(new_action_path, f\"{video_name}_augmented.mp4\")\n",
    "                \n",
    "                print(f\"Guardando: {output_video_path}\")\n",
    "                save_video(augmented_frames, output_video_path)\n",
    "                \n",
    "base_path = 'F:/data/mvfouls/train'\n",
    "actions= videos_path\n",
    "actions_labels_dict = {action: label for action, label in sorted_labels_train}\n",
    "target_count = 200 #Numero objetivo de acciones \"No offence\" después de resamplear\n",
    "\n",
    "resampled_actions = identify_and_resample_no_offence(actions, actions_labels_dict, target_count)\n",
    "navigate_and_resample_videos(base_path, actions, resampled_actions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_action_label_dict(base_path):\n",
    "    action_label_dict = {}  # Diccionario para almacenar las acciones y sus etiquetas\n",
    "\n",
    "    # Recorremos las carpetas dentro de 'F:/data/mvfouls/train'\n",
    "    for folder_name in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        \n",
    "        # Comprobamos si es una carpeta y si el nombre tiene el formato 'action_<id>_augmented'\n",
    "        if os.path.isdir(folder_path) and folder_name.endswith('_augmented'):\n",
    "            action_name = folder_name.split('_augmented')[0]  # Extraemos el nombre de la acción\n",
    "            action_label_dict[action_name] = 'No offence'  # Añadimos la acción con el label 'No offence'\n",
    "\n",
    "    return action_label_dict\n",
    "\n",
    "# Ruta base donde se encuentran las carpetas\n",
    "base_path = 'F:/data/mvfouls/train'\n",
    "\n",
    "# Crear el diccionario de acciones con su label\n",
    "action_label_dict = create_action_label_dict(base_path)\n",
    "\n",
    "# Mostrar el diccionario generado\n",
    "print(len(action_label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb541a0-fc07-4c1f-a397-bc5ba6afbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para renombrar las carpetas de videos aumentados siguiendo el orden de acciones\n",
    "def rename_action_folders_sequential(base_path, start_number):\n",
    "    counter = start_number\n",
    "    for folder_name in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        \n",
    "        # Verificamos si es una carpeta y si tiene el sufijo '_augmented'\n",
    "        if os.path.isdir(folder_path) and folder_name.endswith('_augmented'):\n",
    "            new_folder_name = f\"action_{counter}\"\n",
    "            new_folder_path = os.path.join(base_path, new_folder_name)\n",
    "            print(f\"Renombrando {folder_path} a {new_folder_path}\")\n",
    "            os.rename(folder_path, new_folder_path)\n",
    "            counter += 1  \n",
    "    \n",
    "    print(\"Renombrado secuencial completo.\")\n",
    "\n",
    "\n",
    "base_path = 'F:/data/mvfouls/train' #Ruta donde estan los videos aumentados\n",
    "\n",
    "\n",
    "start_number = 3861 #Acción por la que empezar a renombrar\n",
    "rename_action_folders_sequential(base_path, start_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d65276-0c19-4a74-8934-9430eff03e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#AÑADIMOS NUEVAS ACCIONES AL DICCIONARIO DE LABELS \n",
    "\n",
    "# Suponiendo que tienes este diccionario de acciones con las etiquetas actuales en 'labels'\n",
    "# Ejemplo:\n",
    "# labels = [('action_0', 'Offence'), ('action_1', 'Offence'), ...]\n",
    "\n",
    "# Calcular cuántas nuevas acciones necesitamos para llegar a 3345\n",
    "new_actions_needed = 3944 - len(sorted_labels_train)+1\n",
    "\n",
    "# Generar nuevas acciones con la etiqueta 'No Offence'\n",
    "new_actions = [('action_' + str(i), 'No offence') for i in range(len(sorted_labels_train), len(sorted_labels_train) + new_actions_needed)]\n",
    "\n",
    "# Agregar las nuevas acciones al diccionario\n",
    "updated_labels = sorted_labels_train + new_actions\n",
    "\n",
    "# Verificar el total final y mostrar algunas de las nuevas acciones\n",
    "print(f\"Total de acciones después de la ampliación: {len(updated_labels)}\")\n",
    "print(updated_labels[-1:])  # Mostrar las últimas 10 acciones para verificar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2afe74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016c770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
