{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a28faa7",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En este notebook se crearán los videos correspondientes a las acciones 'Severity' con el objetivo de compensar el desequilibrio del conjunto de datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import vidaug.augmentors as va\n",
    "import random\n",
    "from PIL import ImageOps, Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de lectura de las etiquetas a partir de un json\n",
    "def load_foul_labels(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    action_labels = {}\n",
    "    for action_id, action_data in data['Actions'].items():\n",
    "        label = action_data['Severity']  # Extraer la etiqueta de 'Severity'\n",
    "        action_name = f\"action_{action_id}\"  # Formar el nombre de la acción\n",
    "        action_labels[action_name] = label\n",
    "    \n",
    "    return action_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de etiquetas en un listado ordenado\n",
    "ls = load_foul_labels(\"F:/data/mvfouls/train/annotations.json\")\n",
    "ls = sorted(ls.items())\n",
    "sorted_labels_train = sorted(ls, key=lambda x: int(x[0].split('_')[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para agrupar la ruta de los videos por accion  \n",
    "\n",
    "def group_videos_by_action(root_path, video_extensions=None):\n",
    "    if video_extensions is None:\n",
    "        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv']\n",
    "\n",
    "    grouped_videos = defaultdict(list)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        for file in filenames:\n",
    "            if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "                action_name = os.path.basename(dirpath)  # Nombre de la carpeta contenedora\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                grouped_videos[action_name].append(file_path)\n",
    "    \n",
    "    sorted_actions = sorted(\n",
    "        grouped_videos.items(), \n",
    "        key=lambda x: int(x[0].split('_')[1])  # Extraer número después de \"action_\"\n",
    "    )\n",
    "    return grouped_videos\n",
    "\n",
    "root_path = \"F:/data/mvfouls/train\"\n",
    "videos_path = group_videos_by_action(root_path = root_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815818c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(sorted_labels_train, columns=['action', 'label'])\n",
    "\n",
    "# Contar la frecuencia de cada clase\n",
    "class_counts = Counter(df['label'])\n",
    "\n",
    "# Mostrar la distribución de clases\n",
    "print(\"Distribución de clases:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b01f8",
   "metadata": {},
   "source": [
    "Agrupamos y convertimos las etiquetas según su severidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65866b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de mapeo\n",
    "conversion = {\n",
    "    \"1.0\": \"no card\",\n",
    "    \"2.0\": \"no card\",\n",
    "    \"3.0\": \"yellow card\",\n",
    "    \"4.0\": \"yellow card\",\n",
    "    \"5.0\": \"red card\",\n",
    "    \"\": \"\"  # Estas son No offence no queremos tratar con ellas\n",
    "}\n",
    "\n",
    "# guardamos la conversion\n",
    "updated_labels = [(action, conversion[label]) for action, label in sorted_labels_train]\n",
    "\n",
    "print(updated_labels[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones para cargar los videos y guardar los nuevos creados a partir de la función de data augmentation.\n",
    "\n",
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def save_video(frames, output_path, fps=30):\n",
    "    height, width, layers = frames[0].shape\n",
    "    size = (width, height)\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, size)\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "#Función que identifica las acciones con etiqueta 5.0 y crea una lista aleatoria de acciones para editar   \n",
    "def identify_and_resample_severity(actions, labels, target_count):\n",
    "    no_offence_actions = [action for action, label in labels.items() if label == '5.0']\n",
    "    resampled_actions = resample(no_offence_actions, replace=True, n_samples=target_count, random_state=123)\n",
    "    return resampled_actions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af922cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'F:/data/mvfouls/train'\n",
    "actions= videos_path\n",
    "actions_labels_dict = {action: label for action, label in sorted_labels_train}\n",
    "target_count = 200 #Numero objetivo de acciones \"No offence\" después de resamplear\n",
    "resampled_actions = identify_and_resample_severity(actions, actions_labels_dict, target_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a2663",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Data Augmentation para Videos Etiquetados como 'No offence'\n",
    "\n",
    "Este código implementa un conjunto de funciones para realizar **data augmentation** en videos etiquetados como `'No offence'`, con el propósito de equilibrar un conjunto de datos de entrenamiento. A continuación, se detallan las transformaciones aplicadas y el flujo de procesamiento.\n",
    "\n",
    "## Transformaciones\n",
    "\n",
    "### Transformaciones básicas con `vidaug`\n",
    "- **Rotación horizontal**: Voltea los frames horizontalmente para simular diferentes perspectivas.\n",
    "\n",
    "### Transformaciones adicionales\n",
    "- **`adjust_saturation`**: Ajusta la saturación de los frames para variar la intensidad de los colores.\n",
    "- **`adjust_brightness`**: Modifica el brillo de los frames para simular cambios en la iluminación.\n",
    "- **`adjust_contrast`**: Ajusta el contraste para resaltar o suavizar detalles en los frames.\n",
    "- **`add_random_noise`**: Introduce ruido aleatorio para simular imperfecciones o condiciones de captura.\n",
    "- **`apply_gaussian_blur`**: Aplica un desenfoque gaussiano para suavizar los frames.\n",
    "- **`random_rotation`**: Rota los frames con un ángulo aleatorio dentro de un rango máximo.\n",
    "- **`add_colored_dots`**: Añade puntos semi-transparentes de colores (rojo, negro y blanco) para aumentar la diversidad visual.\n",
    "- **`shear`**: Aplica una transformación de cizallamiento para distorsionar los frames.\n",
    "- **`apply_vignette`**: Agrega un efecto de viñeta para oscurecer los bordes de los frames.\n",
    "- **`grayscale`**: Convierte los frames a escala de grises, manteniendo el formato BGR.\n",
    "- **`edge_enhance`**: Resalta los bordes de los frames mediante un filtro de detección de bordes.\n",
    "\n",
    "## Aplicación en `augment_video`\n",
    "\n",
    "La función `augment_video` recibe una lista de frames y aplica un subconjunto de transformaciones seleccionadas de forma aleatoria o todas, si no se especifica. Combina las transformaciones de `vidaug` con las funciones adicionales para generar videos con mayor diversidad, ideales para mejorar el rendimiento de modelos de machine learning.\n",
    "\n",
    "## Procesamiento y guardado de videos\n",
    "\n",
    "La función `navigate_and_resample_videos` itera sobre una lista de acciones remuestreadas, carga los videos asociados desde una ruta base, aplica un número configurable de transformaciones aleatorias (por defecto, 4) y guarda los videos aumentados en una carpeta específica (`{action}_augmented`). Si la carpeta ya existe, se crea una nueva con un sufijo numérico para evitar conflictos.\n",
    "\n",
    "### Funciones auxiliares\n",
    "- **`load_video`**: Carga los frames de un video desde un archivo.\n",
    "- **`save_video`**: Guarda una lista de frames como un nuevo video en formato MP4.\n",
    "\n",
    "## Flujo general\n",
    "1. Se identifican las acciones etiquetadas como `'No offence'` y se remuestrean para alcanzar un número objetivo.\n",
    "2. Para cada acción, se seleccionan aleatoriamente un número fijo de transformaciones.\n",
    "3. Los videos correspondientes se cargan, transforman con `augment_video` y se guardan en una nueva carpeta.\n",
    "\n",
    "Este enfoque permite generar un conjunto de datos más diverso y equilibrado, adecuado para tareas de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import vidaug.augmentors as va\n",
    "import random\n",
    "\n",
    "seq = va.Sequential([\n",
    "    va.HorizontalFlip(),\n",
    "])\n",
    "\n",
    "def adjust_saturation(image, factor=1.5):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * factor, 0, 255)\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def adjust_brightness(image, factor=1.2):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    hsv[..., 2] = np.clip(hsv[..., 2] * factor, 0, 255)\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def adjust_contrast(image, factor=1.3):\n",
    "    img_float = image.astype(np.float32)\n",
    "    mean = np.mean(img_float, axis=(0, 1))\n",
    "    contrasted = np.clip((img_float - mean) * factor + mean, 0, 255)\n",
    "    return contrasted.astype(np.uint8)\n",
    "\n",
    "def add_random_noise(image, intensity=15):\n",
    "    noise = np.random.randint(-intensity, intensity, image.shape, dtype=np.int16)\n",
    "    noisy_image = np.clip(image.astype(np.int16) + noise, 0, 255)\n",
    "    return noisy_image.astype(np.uint8)\n",
    "\n",
    "def apply_gaussian_blur(image, ksize=(3, 3)):\n",
    "    return cv2.GaussianBlur(image, ksize, 0)\n",
    "\n",
    "def random_rotation(frames, max_angle=10):\n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    rotated_frames = []\n",
    "    for frame in frames:\n",
    "        h, w = frame.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "        rotated = cv2.warpAffine(frame, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "        rotated_frames.append(rotated)\n",
    "    return rotated_frames\n",
    "\n",
    "def add_colored_dots(image, num_dots=500, dot_size=2, alpha=0.6):\n",
    "    overlay = image.copy()\n",
    "    h, w = image.shape[:2]\n",
    "    colors = [(0, 0, 255), (0, 0, 0), (255, 255, 255)]\n",
    "    for _ in range(num_dots):\n",
    "        x, y = random.randint(0, w - 1), random.randint(0, h - 1)\n",
    "        color = random.choice(colors)\n",
    "        cv2.circle(overlay, (x, y), dot_size, color, -1)\n",
    "    return cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "\n",
    "def shear(image, max_shear=0.05):\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = np.float32([[1, random.uniform(-max_shear, max_shear), 0], \n",
    "                    [random.uniform(-max_shear, max_shear), 1, 0]])\n",
    "    sheared_image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    return sheared_image\n",
    "\n",
    "def apply_vignette(image, intensity=0.6):\n",
    "    h, w = image.shape[:2]\n",
    "    kernel_x = cv2.getGaussianKernel(w, w / 2)\n",
    "    kernel_y = cv2.getGaussianKernel(h, h / 2)\n",
    "    kernel = kernel_y * kernel_x.T\n",
    "    mask = 255 * kernel / np.max(kernel)\n",
    "    mask = cv2.normalize(mask, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    vignette = np.copy(image)\n",
    "    for i in range(3):\n",
    "        vignette[:, :, i] = vignette[:, :, i] * (1 - intensity * (1 - mask))\n",
    "    return vignette.astype(np.uint8)\n",
    "\n",
    "def grayscale(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "def edge_enhance(image):\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n",
    "    enhanced = cv2.filter2D(image, -1, kernel)\n",
    "    return np.clip(enhanced, 0, 255).astype(np.uint8)\n",
    "\n",
    "def augment_video(frames, apply_transforms=None):\n",
    "    all_transforms = [\n",
    "        \"vidaug\",\n",
    "        \"saturation\",\n",
    "        \"brightness\",\n",
    "        \"contrast\",\n",
    "        \"noise\",\n",
    "        \"blur\",\n",
    "        \"rotation\",\n",
    "        \"colored_dots\",\n",
    "        \"shear\",\n",
    "        \"vignette\",\n",
    "        \"grayscale\",\n",
    "        \"edge_enhance\"\n",
    "    ]\n",
    "    \n",
    "    if apply_transforms is None:\n",
    "        apply_transforms = all_transforms\n",
    "    \n",
    "    transformed_frames = frames.copy()\n",
    "    \n",
    "    for transform in apply_transforms:\n",
    "        if transform == \"vidaug\":\n",
    "            transformed_frames = seq(transformed_frames)\n",
    "        elif transform == \"saturation\":\n",
    "            transformed_frames = [adjust_saturation(frame) for frame in transformed_frames]\n",
    "        elif transform == \"brightness\":\n",
    "            transformed_frames = [adjust_brightness(frame) for frame in transformed_frames]\n",
    "        elif transform == \"contrast\":\n",
    "            transformed_frames = [adjust_contrast(frame) for frame in transformed_frames]\n",
    "        elif transform == \"noise\":\n",
    "            transformed_frames = [add_random_noise(frame) for frame in transformed_frames]\n",
    "        elif transform == \"blur\":\n",
    "            transformed_frames = [apply_gaussian_blur(frame) for frame in transformed_frames]\n",
    "        elif transform == \"rotation\":\n",
    "            transformed_frames = random_rotation(transformed_frames)\n",
    "        elif transform == \"colored_dots\":\n",
    "            transformed_frames = [add_colored_dots(frame) for frame in transformed_frames]\n",
    "        elif transform == \"shear\":\n",
    "            transformed_frames = [shear(frame) for frame in transformed_frames]\n",
    "        elif transform == \"vignette\":\n",
    "            transformed_frames = [apply_vignette(frame) for frame in transformed_frames]\n",
    "        elif transform == \"grayscale\":\n",
    "            transformed_frames = [grayscale(frame) for frame in transformed_frames]\n",
    "        elif transform == \"edge_enhance\":\n",
    "            transformed_frames = [edge_enhance(frame) for frame in transformed_frames]\n",
    "    \n",
    "    if len(transformed_frames) != len(frames):\n",
    "        transformed_frames = transformed_frames[:len(frames)]\n",
    "    \n",
    "    return np.array(transformed_frames)\n",
    "\n",
    "def navigate_and_resample_videos(base_path, actions, resampled_actions, num_transforms=4):\n",
    "    all_transforms = [\n",
    "        \"vidaug\",\n",
    "        \"saturation\",\n",
    "        \"brightness\",\n",
    "        \"contrast\",\n",
    "        \"noise\",\n",
    "        \"blur\",\n",
    "        \"rotation\",\n",
    "        \"colored_dots\",\n",
    "        \"shear\",\n",
    "        \"vignette\",\n",
    "        \"grayscale\",\n",
    "        \"edge_enhance\"\n",
    "    ]\n",
    "\n",
    "    for action in resampled_actions:\n",
    "        if action in actions:\n",
    "            video_list = actions[action]\n",
    "            selected_transforms = random.sample(all_transforms, min(num_transforms, len(all_transforms)))\n",
    "            print(f\"Transformaciones para la acción '{action}': {selected_transforms}\")\n",
    "            \n",
    "            base_folder_name = f\"{action}_augmented\"\n",
    "            new_action_path = os.path.join(base_path, base_folder_name)\n",
    "            suffix = 1\n",
    "            while os.path.exists(new_action_path):\n",
    "                new_action_path = os.path.join(base_path, f\"{base_folder_name}_{suffix}\")\n",
    "                suffix += 1\n",
    "            os.makedirs(new_action_path)\n",
    "\n",
    "            for video_file in video_list:\n",
    "                video_path = os.path.join(base_path, video_file)\n",
    "                frames = load_video(video_path)\n",
    "                if len(frames) == 0:\n",
    "                    continue\n",
    "\n",
    "                augmented_frames = augment_video(frames, apply_transforms=selected_transforms)\n",
    "                \n",
    "                video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "                output_video_path = os.path.join(new_action_path, f\"{video_name}_augmented.mp4\")\n",
    "                print(f\"Guardando clip: {output_video_path}\")\n",
    "                save_video(augmented_frames, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7dbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "navigate_and_resample_videos(base_path, actions, resampled_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para renombrar las carpetas de videos aumentados siguiendo el orden de acciones\n",
    "def rename_action_folders_sequential(base_path, start_number):\n",
    "    counter = start_number\n",
    "    for folder_name in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        \n",
    "        # Verificamos si es una carpeta y si contiene 'augmented' en el nombre\n",
    "        if os.path.isdir(folder_path) and 'augmented' in folder_name:\n",
    "            new_folder_name = f\"action_{counter}\"\n",
    "            new_folder_path = os.path.join(base_path, new_folder_name)\n",
    "            print(f\"Renombrando {folder_path} a {new_folder_path}\")\n",
    "            os.rename(folder_path, new_folder_path)\n",
    "            \n",
    "            counter += 1 \n",
    "    \n",
    "    print(\"Renombrado secuencial completo.\")\n",
    "\n",
    "# Ruta base \n",
    "base_path = 'F:/data/mvfouls/train'\n",
    "\n",
    "start_number = 3853  # Acción por la que empezar a renombrar\n",
    "rename_action_folders_sequential(base_path, start_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc47f6e",
   "metadata": {},
   "source": [
    "# EN EL 3175 empiezan las 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beced15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#AÑADIMOS NUEVAS ACCIONES AL DICCIONARIO DE LABELS \n",
    "\n",
    "# Calcular cuántas nuevas acciones necesitamos para llegar a 3345\n",
    "new_actions_needed = 3174 - len(sorted_labels_train)+1\n",
    "\n",
    "# Generar nuevas acciones con la etiqueta 'No Offence'\n",
    "new_actions = [('action_' + str(i), '3.0') for i in range(len(sorted_labels_train), len(sorted_labels_train) + new_actions_needed)]\n",
    "\n",
    "# Agregar las nuevas acciones al diccionario\n",
    "updated_labels = sorted_labels_train + new_actions\n",
    "\n",
    "# Verificar el total final y mostrar algunas de las nuevas acciones\n",
    "print(f\"Total de acciones después de la ampliación: {len(updated_labels)}\")\n",
    "print(updated_labels[:])  # Mostrar las últimas 10 acciones para verificar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d54fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular cuántas nuevas acciones necesitamos para llegar a 3345\n",
    "new_actions_needed = 4052 - len(updated_labels)+1\n",
    "\n",
    "# Crear las nuevas acciones con etiqueta '5.0' desde el último índice actual\n",
    "start_index = int(updated_labels[-1][0].split('_')[1]) + 1  # último índice + 1\n",
    "\n",
    "# Generar nuevas acciones\n",
    "new_actions_5_0 = [('action_' + str(i), '5.0') for i in range(start_index, start_index + new_actions_needed)]\n",
    "\n",
    "# Agregar al listado actualizado\n",
    "updated_labels += new_actions_5_0\n",
    "\n",
    "# Verificación\n",
    "print(f\"Total final de acciones: {len(updated_labels)}\")\n",
    "print(\"Últimas acciones añadidas:\")\n",
    "print(updated_labels[-new_actions_needed:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64aca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "3193- 3174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e08137",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_labels[2917:3100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2248a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
